{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<table bgcolor=#ffffff align=\"center\" width=\"100%\" noborder>\n",
    "    <tr>\n",
    "        <td align=\"left\" width=\"30%\"><img src=\"images/IST_logo.png\" width=\"50%\"></td>\n",
    "        <td width=\"40%\"></td>\n",
    "        <td align=\"right\" width=\"30%\"><img src=\"images/ds_logo.png\" width=\"25%\"></td>\n",
    "    </tr>\n",
    "    <tr><td align=\"left\" width=\"30%\"></td>\n",
    "        <td width=\"40%\"><p align=\"center\"><img src=\"images/title.png\"</td>\n",
    "        <td align=\"right\" width=\"30%\"></td>\n",
    "    </tr>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 align=\"center\" style=\"font-family:Arial;color:#6c6c6c;font-size:30px;\">Lab 3: Classification</h1>\n",
    "\n",
    "Classification is one of the major tasks in data science, and can be performed through <code>sklearn</code> package \n",
    "and its multiple subpackages. The image below summarizes the different major classification techniques and the \n",
    "corresponding implementation packages in <code>sklearn</code>.\n",
    "\n",
    "<p align=\"center\"><img src=\"images/classification.png\" width=\"50%\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2 style=\"font-family:Arial;color:#6c6c6c;font-size:25px;\">Training Models</h2>\n",
    "\n",
    "Whenever we are in the presence of a classification problem, the first thing to do is to identify the <i>target</i> or\n",
    "<i>class</i>, which is the variable to predict. The type of the target variable determines the kind of operation to \n",
    "perform: targets with just a few values allow for a <strong>classification</strong> task, while real-valued targets \n",
    "require a <strong>prediction</strong> one.\n",
    "\n",
    "In the presence of a classification task, identifying the target balancing is mandatory, in order to choose the most \n",
    "adequate balancing strategy (see <a href=\"Lab23_balancing.ipynb\">Data balancing</a>) and elect the best metrics to \n",
    "evaluate the results achieved."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3 style=\"font-family:Arial;color:#6c6c6c;font-size:20px;font-style:italic;\">Training strategy</h3>\n",
    "\n",
    "After applying balancing techniques, if required, we need to choose the best training strategy to train classification\n",
    "models. The training strategy concerns with the way to get the <strong>train and test datasets</strong>, which is done\n",
    " in accordance to data characteristics:\n",
    "- <strong>k-fold cross validation</strong> (<code>StratifiedKFold</code>): used in the presence of a few thousand records;\n",
    "- <strong>hold-out</strong> (<code>train_test_split</code>): used in the presence of large thousands of records;\n",
    "- <strong>sample hold-out</strong>: used in the presence of millions of records.\n",
    "\n",
    "With the data split, we proceed to create the prediction model. However, there is a plethora of techniques and  \n",
    "extensions, with an infinite number of different parametrisations, and the choice of the best one to apply can only be \n",
    "done by comparing their results in our data. Additionally, each technique works better for data with some specific \n",
    "characteristics, which demands the application of some data preparation transformations.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv('data/iris.csv')\n",
    "y: np.ndarray = data.pop('class').values\n",
    "X: np.ndarray = data.values\n",
    "labels: np.ndarray = pd.unique(y)\n",
    "\n",
    "trnX, tstX, trnY, tstY = train_test_split(X, y, train_size=0.7, stratify=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As noted above, the train of classification models is achieved through <code>sklearn</code> package. Since it is \n",
    "constructed over the <code>numpy</code> package, we need to present numpy arrays <code>ndarray</code> as parameters \n",
    "for the different methods, like <code>train_test_split</code>.\n",
    "In mathematical terms, classification aims to map the data <i>X</i> to values into the domain of the target \n",
    "variable, call it <i>y</i>.\n",
    "After loading the data, in <i>data</i> dataframe, we need to separate the target variable from the rest of the data, \n",
    "since it plays a different role in the training procedure. Through the application of the <code>pop</code> method, we\n",
    "get the <i>class</i> variable, and simultaneously removing it from the dataframe. So, <i>y</i> will keep the \n",
    "<code>ndarray</code> with the target variable for each record and <i>X</i> the <code>ndarray</code> containing the\n",
    "records themselves.\n",
    "\n",
    "The <code>train_test_split</code> receives both <i>X</i> and <i>y</i> as the data to split, and returns both of them \n",
    "split in two: <i>trnX</i> will contain <code>trains_size</code> of <i>X</i> and <i>tstX</i> will contain the remaining \n",
    "30%, and the same for <i>y</i>. \n",
    "\n",
    "Note the <code>stratify</code> parameter - when <code>y</code> it establishes that the split will keep\n",
    "the original distribution of data, which is mandatory whenever the data is not balanced, and usually advisable for the\n",
    "majority of situations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4 style=\"font-family:Arial;color:#6c6c6c;font-size:20px;font-style:italic;\">Estimators and Models</h4>\n",
    "\n",
    "In <code>sklearn</code>, a <strong>estimator</strong> is an object of an extension of the <code>BaseEstimator</code> \n",
    "class, which implements the <code>fit</code> and <code>predict</code> methods. Beside these, it also implements the \n",
    "<code>score</code> method. Estimators parametrization are done through passing the different choices as parameters\n",
    "to their constructors methods.\n",
    "\n",
    "Note that in sklearn <strong>there is no class for representing the models learnt</strong>, but their effects are \n",
    "reachable through the estimator object. Indeed, an <i>estimator</i> is the result of parametrising a learning technique, \n",
    "trained over a particular dataset, creating a <i>classification model</i>.  \n",
    "\n",
    "<table noborder>\n",
    "    <tr><th><p text-align:\"center\">Estimators Methods</th></tr>\n",
    "    <tr><th><p text-align:\"center\"></th></tr>\n",
    "    <tr><td><p text-align:\"left\"><code><b>fit(trnX: np.ndarray, trnY: np.ndarray)</b></code></td></tr>\n",
    "    <tr><td><p text-align:\"left\">trains the classifier over the data <i>trnX</i> labeled according to <i>trnY</i>, \n",
    "        creating an internal model</td></tr>\n",
    "    <tr><td><p text-align:\"left\"><code><b>predict(trnX: np.ndarray) -> np.ndarray</b></code></td></tr>\n",
    "    <tr><td><p text-align:\"left\">applies the learnt model to the training data in <i>trnX</i> and returns their \n",
    "        predicted labels</td></tr>\n",
    "    <tr><td><p text-align:\"left\"><code><b>score(tstX: np.ndarray, tstY: np.ndarray) -> float</b></code></td></tr>\n",
    "    <tr><td><p text-align:\"left\">applies the model to <i>tstX</i> and compares the predicted labels to the labels\n",
    "        in <i>tstY</i>, computing model's mean accuracy on the given data</td></tr>\n",
    "</table>\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among the techniques that we are going to use, are: <code>GaussianNB</code>, <code>KNeighborsClassifier</code>, \n",
    "<code>DecisionTreeClassifier</code>, <code>RandomForestClassifier</code> and <code>GradientBoostingClassifier</code>.\n",
    "\n",
    "The rest of this module is organized in a similar way for each one of the classification techniques: it first succinctly \n",
    "describes the technique and its main parameters, then we train different models through different parametrisations of \n",
    "the technique, using a 70%train-30%test split strategy, and evaluate the accuracy of each model as explained in \n",
    "<a href=\"Lab4_evaluation.ipynb\">Lab 4 - Models evaluation</a>, comparing the different results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table bgcolor=#ffffff align=\"center\" width=\"100%\" noborder>\n",
    "    <tr>\n",
    "        <td align=\"center\" width=\"30%\"><a href=\"Lab2_preparation.ipynb\"><img src=\"images/prev.png\"></a></td>\n",
    "        <td width=\"40%\"></td>\n",
    "        <td align=\"center\" width=\"30%\"><a href=\"Lab31_naivebayes.ipynb\"><img src=\"images/next.png\"></a></td>\n",
    "    </tr>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}