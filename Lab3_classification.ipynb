{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<table bgcolor=#ffffff align=\"center\" width=\"100%\" noborder>\n",
    "    <tr>\n",
    "        <td align=\"left\" width=\"30%\"><img src=\"images/IST_logo.png\" width=\"50%\"></td>\n",
    "        <td width=\"40%\"></td>\n",
    "        <td align=\"right\" width=\"30%\"><img src=\"images/ds_logo.png\" width=\"25%\">\n",
    "    </tr>\n",
    "</table>\n",
    "<h1 align=\"center\" style=\"font-family:Arial;color:#00004d;font-size:40px;\">Data Science Labs</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2 align=\"center\" style=\"font-family:Arial;color:#6c6c6c;font-size:30px;\">Lab 3: Classification</h2>\n",
    "\n",
    "Classification is one of the major tasks in data science, and can be performed through <code>sklearn</code> package \n",
    "and its multiple subpackages. The image below summarizes the different major classification techniques and the \n",
    "corresponding implementation packages in <code>sklearn</code>\n",
    "\n",
    "<p align=\"center\"><img src=\"images/classification.png\" width=\"50%\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3 style=\"font-family:Arial;color:#6c6c6c;font-size:25px;\">Problem Formulation</h3>\n",
    "Whenever we are in the presence of a classification problem, the first thing to do is to identify the <strong>target</strong>,\n",
    "which is the variable to predict. \n",
    "The type of the target variable determines the kind of prediction to perform: targets with just a few values allow for a \n",
    "classification task, while real-valued targets require a regression one.\n",
    "\n",
    "In the presence of a classification task, identifying the target balancing is mandatory, in order to choose the most \n",
    "adequate balancing strategy (see <a href=\"Lab23_balancing.ipynb\">Data balancing</a>) and elect the best metrics to \n",
    "evaluate the results achieved.\n",
    "\n",
    "\n",
    "In order to train a model, we need to choose the best training strategy, which is done concerning the data characteristics:\n",
    "- <strong>k-fold cross validation</strong> (<code>StratifiedKFold</code>): used in the presence of a few thousand records;\n",
    "- <strong>train and test split</strong> (<code>train_test_split</code>): used in the presence of large thousands of records;\n",
    "- <strong>sample train and test sets</strong>: used in the presence of millions of records.\n",
    "         \n",
    "\n",
    "\n",
    "The rest of this module is organized in a similar way for each one of the classification techniques: it first succinctly describes \n",
    "the technique and its main parameters, then train different models with a example dataset and evaluates the performance\n",
    "of each model, comparing the different results.\n",
    "\n",
    "For each one of the training steps, we use a 70%train-30%test split strategy, and evaluate models performance trough its\n",
    "accuracy. Other evaluation strategies can be found in the <a href=\"Lab4_evaluation.ipynb\">Lab 4 - Models evaluation</a>\n",
    "module. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[15,  0,  0],\n       [ 0, 13,  2],\n       [ 0,  2, 13]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%load functions.ipynb\n",
    "import ipynb.fs.defs.functions as func\n",
    "\n",
    "data = pd.read_csv('data/iris.csv')\n",
    "y = data.pop('target').values\n",
    "X = data.values\n",
    "labels = pd.unique(y)\n",
    "\n",
    "trX, tsX, trY, tsY = train_test_split(X, y, train_size=0.7, stratify=y)\n",
    "\n",
    "nb = GaussianNB()\n",
    "model = nb.fit(trX, trY)\n",
    "prdY = model.predict(tsX)\n",
    "\n",
    "cnf_mtx = confusion_matrix(tsY, prdY, labels)\n",
    "#func.plot_confusion_matrix(cnf_mtx, labels)\n",
    "cnf_mtx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4 style=\"font-family:Arial;color:#6c6c6c;font-size:20px;font-style:italic;\"></h4>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3 style=\"font-family:Arial;color:#6c6c6c;font-size:25px;\">Naive Bayes</h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table bgcolor=#ffffff align=\"center\" width=\"100%\" noborder>\n",
    "    <tr>\n",
    "        <td align=\"center\" width=\"30%\"><a href=\"Lab2_preparation.ipynb\"><img src=\"images/prev.png\"></a></td>\n",
    "        <td width=\"40%\"></td>\n",
    "        <td align=\"center\" width=\"30%\"><a href=\"Lab4.ipynb\"><img src=\"images/next.png\"></a></td>\n",
    "    </tr>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}